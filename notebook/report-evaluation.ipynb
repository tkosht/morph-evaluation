{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeCab, SentencePiece の精度評価\n",
    "\n",
    "- 評価データセット：ldcc\n",
    "- 評価方法：pipeline\n",
    "    - ../model/\n",
    "        - pipe-jptokenizermecab.gz\n",
    "        - pipe-jptokenizersentencepiece.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from classify_ldcc import DocRecord, DatasetLdcc\n",
    "from classify_ldcc import JpTokenizerMeCab, JpTokenizerSentencePiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelineの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from classify_ldcc import ident_tokener, SparsetoDense, Transer\n",
    "os.chdir(\"../\")\n",
    "pipe_mecab = joblib.load(\"model/pipe-jptokenizermecab.gz\")\n",
    "pipe_sentencepiece = joblib.load(\"model/pipe-jptokenizersentencepiece.gz\")\n",
    "os.chdir(\"notebook/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tokenizer',\n",
       "                 <classify_ldcc.JpTokenizerMeCab object at 0x7ff1b4edb978>),\n",
       "                ('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=False, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf...\n",
       "                 LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                colsample_bytree=1.0, importance_type='gain',\n",
       "                                learning_rate=0.1, max_depth=-1,\n",
       "                                min_child_samples=20, min_child_weight=0.001,\n",
       "                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,\n",
       "                                num_class=9, num_leaves=31, objective='softmax',\n",
       "                                random_state=None, reg_alpha=0.0,\n",
       "                                reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "                                subsample_for_bin=200000, subsample_freq=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tokenizer',\n",
       "                 <classify_ldcc.JpTokenizerSentencePiece object at 0x7ff131b16128>),\n",
       "                ('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=False, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, sm...\n",
       "                 LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                colsample_bytree=1.0, importance_type='gain',\n",
       "                                learning_rate=0.1, max_depth=-1,\n",
       "                                min_child_samples=20, min_child_weight=0.001,\n",
       "                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,\n",
       "                                num_class=9, num_leaves=31, objective='softmax',\n",
       "                                random_state=None, reg_alpha=0.0,\n",
       "                                reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "                                subsample_for_bin=200000, subsample_freq=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>cpu_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JpTokenizerMeCab</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>61.854007</td>\n",
       "      <td>296.743731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JpTokenizerSentencePiece</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954772</td>\n",
       "      <td>93.701337</td>\n",
       "      <td>543.958018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JpTokenizerMeCab</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952058</td>\n",
       "      <td>60.941810</td>\n",
       "      <td>289.572545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JpTokenizerSentencePiece</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952510</td>\n",
       "      <td>94.718693</td>\n",
       "      <td>547.378444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JpTokenizerMeCab</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943917</td>\n",
       "      <td>61.125902</td>\n",
       "      <td>292.175544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  tokenizer  train_acc  valid_acc  elapsed_time    cpu_time\n",
       "0          JpTokenizerMeCab        1.0   0.940299     61.854007  296.743731\n",
       "1  JpTokenizerSentencePiece        1.0   0.954772     93.701337  543.958018\n",
       "2          JpTokenizerMeCab        1.0   0.952058     60.941810  289.572545\n",
       "3  JpTokenizerSentencePiece        1.0   0.952510     94.718693  547.378444\n",
       "4          JpTokenizerMeCab        1.0   0.943917     61.125902  292.175544"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_csv = \"../data/result.csv\"\n",
    "columns = [\"tokenizer\", \"train_acc\", \"valid_acc\", \"elapsed_time\", \"cpu_time\"]\n",
    "df = pandas.read_csv(result_csv, header=None, names=columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回数情報を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>cpu_time</th>\n",
       "      <th>times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JpTokenizerMeCab</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>61.854007</td>\n",
       "      <td>296.743731</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JpTokenizerSentencePiece</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954772</td>\n",
       "      <td>93.701337</td>\n",
       "      <td>543.958018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JpTokenizerMeCab</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952058</td>\n",
       "      <td>60.941810</td>\n",
       "      <td>289.572545</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JpTokenizerSentencePiece</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952510</td>\n",
       "      <td>94.718693</td>\n",
       "      <td>547.378444</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JpTokenizerMeCab</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943917</td>\n",
       "      <td>61.125902</td>\n",
       "      <td>292.175544</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  tokenizer  train_acc  valid_acc  elapsed_time    cpu_time  \\\n",
       "0          JpTokenizerMeCab        1.0   0.940299     61.854007  296.743731   \n",
       "1  JpTokenizerSentencePiece        1.0   0.954772     93.701337  543.958018   \n",
       "2          JpTokenizerMeCab        1.0   0.952058     60.941810  289.572545   \n",
       "3  JpTokenizerSentencePiece        1.0   0.952510     94.718693  547.378444   \n",
       "4          JpTokenizerMeCab        1.0   0.943917     61.125902  292.175544   \n",
       "\n",
       "   times  \n",
       "0      1  \n",
       "1      1  \n",
       "2      2  \n",
       "3      2  \n",
       "4      3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizers = df[\"tokenizer\"].drop_duplicates()\n",
    "n = len(df) // 2\n",
    "times = numpy.array([list(range(1, n+1)) for tkr in tokenizers]).T.ravel()\n",
    "times\n",
    "df[\"times\"] = times[:len(df)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実行時間を評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>JpTokenizerMeCab</th>\n",
       "      <th>JpTokenizerSentencePiece</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">valid_acc</th>\n",
       "      <th>1</th>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.954772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.952058</td>\n",
       "      <td>0.952510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.943917</td>\n",
       "      <td>0.952962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.954772</td>\n",
       "      <td>0.962913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.956128</td>\n",
       "      <td>0.960199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.952058</td>\n",
       "      <td>0.958842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.949344</td>\n",
       "      <td>0.958842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.947083</td>\n",
       "      <td>0.962460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.945726</td>\n",
       "      <td>0.958842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.948892</td>\n",
       "      <td>0.954319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "tokenizer        JpTokenizerMeCab  JpTokenizerSentencePiece\n",
       "          times                                            \n",
       "valid_acc 1              0.940299                  0.954772\n",
       "          2              0.952058                  0.952510\n",
       "          3              0.943917                  0.952962\n",
       "          4              0.954772                  0.962913\n",
       "          5              0.956128                  0.960199\n",
       "          6              0.952058                  0.958842\n",
       "          7              0.949344                  0.958842\n",
       "          8              0.947083                  0.962460\n",
       "          9              0.945726                  0.958842\n",
       "          10             0.948892                  0.954319"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_acc_df = df.pivot(index=\"tokenizer\", columns=\"times\", values=[\"valid_acc\", \"train_acc\", \"elapsed_time\", \"cpu_time\"]).T\n",
    "#_acc_df[\"mean\"] = pvdf.mean(axis=1)\n",
    "#_acc_df[\"std\"] = pvdf.std(axis=1)\n",
    "_acc_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 経過時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>times</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>JpTokenizerMeCab</th>\n",
       "      <td>61.854007</td>\n",
       "      <td>60.941810</td>\n",
       "      <td>61.125902</td>\n",
       "      <td>61.077122</td>\n",
       "      <td>61.930245</td>\n",
       "      <td>60.873570</td>\n",
       "      <td>61.346454</td>\n",
       "      <td>60.805689</td>\n",
       "      <td>60.799273</td>\n",
       "      <td>60.492267</td>\n",
       "      <td>...</td>\n",
       "      <td>61.262253</td>\n",
       "      <td>61.133369</td>\n",
       "      <td>61.754891</td>\n",
       "      <td>61.204561</td>\n",
       "      <td>61.280280</td>\n",
       "      <td>60.941494</td>\n",
       "      <td>61.124489</td>\n",
       "      <td>61.424840</td>\n",
       "      <td>61.337754</td>\n",
       "      <td>0.599082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JpTokenizerSentencePiece</th>\n",
       "      <td>93.701337</td>\n",
       "      <td>94.718693</td>\n",
       "      <td>92.480894</td>\n",
       "      <td>93.132043</td>\n",
       "      <td>92.901012</td>\n",
       "      <td>93.051905</td>\n",
       "      <td>92.675434</td>\n",
       "      <td>93.246276</td>\n",
       "      <td>92.686435</td>\n",
       "      <td>94.048845</td>\n",
       "      <td>...</td>\n",
       "      <td>93.473539</td>\n",
       "      <td>93.650603</td>\n",
       "      <td>93.477266</td>\n",
       "      <td>94.049311</td>\n",
       "      <td>93.301715</td>\n",
       "      <td>94.015320</td>\n",
       "      <td>93.246925</td>\n",
       "      <td>94.315198</td>\n",
       "      <td>93.574950</td>\n",
       "      <td>0.744620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "times                             1          2          3          4  \\\n",
       "tokenizer                                                              \n",
       "JpTokenizerMeCab          61.854007  60.941810  61.125902  61.077122   \n",
       "JpTokenizerSentencePiece  93.701337  94.718693  92.480894  93.132043   \n",
       "\n",
       "times                             5          6          7          8  \\\n",
       "tokenizer                                                              \n",
       "JpTokenizerMeCab          61.930245  60.873570  61.346454  60.805689   \n",
       "JpTokenizerSentencePiece  92.901012  93.051905  92.675434  93.246276   \n",
       "\n",
       "times                             9         10  ...         93         94  \\\n",
       "tokenizer                                       ...                         \n",
       "JpTokenizerMeCab          60.799273  60.492267  ...  61.262253  61.133369   \n",
       "JpTokenizerSentencePiece  92.686435  94.048845  ...  93.473539  93.650603   \n",
       "\n",
       "times                            95         96         97         98  \\\n",
       "tokenizer                                                              \n",
       "JpTokenizerMeCab          61.754891  61.204561  61.280280  60.941494   \n",
       "JpTokenizerSentencePiece  93.477266  94.049311  93.301715  94.015320   \n",
       "\n",
       "times                            99        100       mean       std  \n",
       "tokenizer                                                            \n",
       "JpTokenizerMeCab          61.124489  61.424840  61.337754  0.599082  \n",
       "JpTokenizerSentencePiece  93.246925  94.315198  93.574950  0.744620  \n",
       "\n",
       "[2 rows x 102 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edf = _acc_df.loc[\"elapsed_time\"].dropna().T\n",
    "edf[\"mean\"] = edf.mean(axis=1)\n",
    "edf[\"std\"] = edf.std(axis=1)\n",
    "edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JpTokenizerMeCab: 1.0 min (0.6 sec)\n",
      "JpTokenizerSentencePiece: 1.6 min (0.7 sec)\n"
     ]
    }
   ],
   "source": [
    "for tkr, m, s in edf[[\"mean\", \"std\"]].reset_index().values:\n",
    "    print(f\"{tkr}: {m/60:.1f} min ({s:.1f} sec)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>times</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>JpTokenizerMeCab</th>\n",
       "      <td>296.743731</td>\n",
       "      <td>289.572545</td>\n",
       "      <td>292.175544</td>\n",
       "      <td>290.710029</td>\n",
       "      <td>298.243288</td>\n",
       "      <td>288.990884</td>\n",
       "      <td>292.800738</td>\n",
       "      <td>290.656328</td>\n",
       "      <td>289.569884</td>\n",
       "      <td>288.375333</td>\n",
       "      <td>...</td>\n",
       "      <td>293.003050</td>\n",
       "      <td>292.353700</td>\n",
       "      <td>296.096029</td>\n",
       "      <td>291.818412</td>\n",
       "      <td>293.606473</td>\n",
       "      <td>290.806997</td>\n",
       "      <td>291.328865</td>\n",
       "      <td>294.110273</td>\n",
       "      <td>293.350750</td>\n",
       "      <td>3.965812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JpTokenizerSentencePiece</th>\n",
       "      <td>543.958018</td>\n",
       "      <td>547.378444</td>\n",
       "      <td>533.848559</td>\n",
       "      <td>535.987757</td>\n",
       "      <td>537.832567</td>\n",
       "      <td>536.450868</td>\n",
       "      <td>537.144222</td>\n",
       "      <td>537.024407</td>\n",
       "      <td>536.028281</td>\n",
       "      <td>543.482934</td>\n",
       "      <td>...</td>\n",
       "      <td>540.933809</td>\n",
       "      <td>540.183844</td>\n",
       "      <td>540.746575</td>\n",
       "      <td>541.801440</td>\n",
       "      <td>540.050591</td>\n",
       "      <td>542.457190</td>\n",
       "      <td>537.523537</td>\n",
       "      <td>543.682308</td>\n",
       "      <td>540.473576</td>\n",
       "      <td>4.804031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "times                              1           2           3           4  \\\n",
       "tokenizer                                                                  \n",
       "JpTokenizerMeCab          296.743731  289.572545  292.175544  290.710029   \n",
       "JpTokenizerSentencePiece  543.958018  547.378444  533.848559  535.987757   \n",
       "\n",
       "times                              5           6           7           8  \\\n",
       "tokenizer                                                                  \n",
       "JpTokenizerMeCab          298.243288  288.990884  292.800738  290.656328   \n",
       "JpTokenizerSentencePiece  537.832567  536.450868  537.144222  537.024407   \n",
       "\n",
       "times                              9          10  ...          93          94  \\\n",
       "tokenizer                                         ...                           \n",
       "JpTokenizerMeCab          289.569884  288.375333  ...  293.003050  292.353700   \n",
       "JpTokenizerSentencePiece  536.028281  543.482934  ...  540.933809  540.183844   \n",
       "\n",
       "times                             95          96          97          98  \\\n",
       "tokenizer                                                                  \n",
       "JpTokenizerMeCab          296.096029  291.818412  293.606473  290.806997   \n",
       "JpTokenizerSentencePiece  540.746575  541.801440  540.050591  542.457190   \n",
       "\n",
       "times                             99         100        mean       std  \n",
       "tokenizer                                                               \n",
       "JpTokenizerMeCab          291.328865  294.110273  293.350750  3.965812  \n",
       "JpTokenizerSentencePiece  537.523537  543.682308  540.473576  4.804031  \n",
       "\n",
       "[2 rows x 102 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf = _acc_df.loc[\"cpu_time\"].dropna().T\n",
    "cdf[\"mean\"] = cdf.mean(axis=1)\n",
    "cdf[\"std\"] = cdf.std(axis=1)\n",
    "cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JpTokenizerMeCab: 4.9 min (4.0 sec)\n",
      "JpTokenizerSentencePiece: 9.0 min (4.8 sec)\n"
     ]
    }
   ],
   "source": [
    "for tkr, m, s in cdf[[\"mean\", \"std\"]].reset_index().values:\n",
    "    print(f\"{tkr}: {m/60:.1f} min ({s:.1f} sec)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 精度評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tokenizer</th>\n",
       "      <th>JpTokenizerMeCab</th>\n",
       "      <th>JpTokenizerSentencePiece</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>times</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.954772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.952058</td>\n",
       "      <td>0.952510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.943917</td>\n",
       "      <td>0.952962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.954772</td>\n",
       "      <td>0.962913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.956128</td>\n",
       "      <td>0.960199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.952058</td>\n",
       "      <td>0.958842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.949344</td>\n",
       "      <td>0.958842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.947083</td>\n",
       "      <td>0.962460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.945726</td>\n",
       "      <td>0.958842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.948892</td>\n",
       "      <td>0.954319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.952510</td>\n",
       "      <td>0.959747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.941655</td>\n",
       "      <td>0.947987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.951606</td>\n",
       "      <td>0.957033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.950249</td>\n",
       "      <td>0.960651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.948892</td>\n",
       "      <td>0.954319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.939846</td>\n",
       "      <td>0.952058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.943464</td>\n",
       "      <td>0.950249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.944821</td>\n",
       "      <td>0.951153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.943917</td>\n",
       "      <td>0.953867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.951606</td>\n",
       "      <td>0.955224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.944369</td>\n",
       "      <td>0.954319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.952058</td>\n",
       "      <td>0.957938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.949796</td>\n",
       "      <td>0.955676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.943917</td>\n",
       "      <td>0.958842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.948892</td>\n",
       "      <td>0.960199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.944369</td>\n",
       "      <td>0.950249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.947987</td>\n",
       "      <td>0.958842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.945274</td>\n",
       "      <td>0.956128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.953415</td>\n",
       "      <td>0.957938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.942560</td>\n",
       "      <td>0.950249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.953415</td>\n",
       "      <td>0.961104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.943012</td>\n",
       "      <td>0.956581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.941655</td>\n",
       "      <td>0.956581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.953415</td>\n",
       "      <td>0.952962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.951153</td>\n",
       "      <td>0.960651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.949796</td>\n",
       "      <td>0.961104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.950701</td>\n",
       "      <td>0.955676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.951153</td>\n",
       "      <td>0.954319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.940751</td>\n",
       "      <td>0.953415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.947535</td>\n",
       "      <td>0.952510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.944369</td>\n",
       "      <td>0.949796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.957033</td>\n",
       "      <td>0.960651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.945726</td>\n",
       "      <td>0.950701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.956128</td>\n",
       "      <td>0.961556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.943012</td>\n",
       "      <td>0.956581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.954319</td>\n",
       "      <td>0.958390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.956581</td>\n",
       "      <td>0.957938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.952058</td>\n",
       "      <td>0.952058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.949344</td>\n",
       "      <td>0.952962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.950701</td>\n",
       "      <td>0.954772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.954772</td>\n",
       "      <td>0.960651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.946178</td>\n",
       "      <td>0.946178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.945274</td>\n",
       "      <td>0.956581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.944369</td>\n",
       "      <td>0.955224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.945274</td>\n",
       "      <td>0.952510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.938489</td>\n",
       "      <td>0.949344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.945274</td>\n",
       "      <td>0.952510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.947083</td>\n",
       "      <td>0.955676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.950701</td>\n",
       "      <td>0.956128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.950701</td>\n",
       "      <td>0.962913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "tokenizer  JpTokenizerMeCab  JpTokenizerSentencePiece\n",
       "times                                                \n",
       "1                  0.940299                  0.954772\n",
       "2                  0.952058                  0.952510\n",
       "3                  0.943917                  0.952962\n",
       "4                  0.954772                  0.962913\n",
       "5                  0.956128                  0.960199\n",
       "...                     ...                       ...\n",
       "96                 0.938489                  0.949344\n",
       "97                 0.945274                  0.952510\n",
       "98                 0.947083                  0.955676\n",
       "99                 0.950701                  0.956128\n",
       "100                0.950701                  0.962913\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df = _acc_df.loc[\"valid_acc\"].dropna()\n",
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>times</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>JpTokenizerSentencePiece</th>\n",
       "      <td>0.954772</td>\n",
       "      <td>0.952510</td>\n",
       "      <td>0.952962</td>\n",
       "      <td>0.962913</td>\n",
       "      <td>0.960199</td>\n",
       "      <td>0.958842</td>\n",
       "      <td>0.958842</td>\n",
       "      <td>0.962460</td>\n",
       "      <td>0.958842</td>\n",
       "      <td>0.954319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956581</td>\n",
       "      <td>0.955224</td>\n",
       "      <td>0.952510</td>\n",
       "      <td>0.949344</td>\n",
       "      <td>0.952510</td>\n",
       "      <td>0.955676</td>\n",
       "      <td>0.956128</td>\n",
       "      <td>0.962913</td>\n",
       "      <td>95.578924</td>\n",
       "      <td>0.374516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JpTokenizerMeCab</th>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.952058</td>\n",
       "      <td>0.943917</td>\n",
       "      <td>0.954772</td>\n",
       "      <td>0.956128</td>\n",
       "      <td>0.952058</td>\n",
       "      <td>0.949344</td>\n",
       "      <td>0.947083</td>\n",
       "      <td>0.945726</td>\n",
       "      <td>0.948892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945274</td>\n",
       "      <td>0.944369</td>\n",
       "      <td>0.945274</td>\n",
       "      <td>0.938489</td>\n",
       "      <td>0.945274</td>\n",
       "      <td>0.947083</td>\n",
       "      <td>0.950701</td>\n",
       "      <td>0.950701</td>\n",
       "      <td>94.865219</td>\n",
       "      <td>0.462855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "times                            1         2         3         4         5  \\\n",
       "tokenizer                                                                    \n",
       "JpTokenizerSentencePiece  0.954772  0.952510  0.952962  0.962913  0.960199   \n",
       "JpTokenizerMeCab          0.940299  0.952058  0.943917  0.954772  0.956128   \n",
       "\n",
       "times                            6         7         8         9        10  \\\n",
       "tokenizer                                                                    \n",
       "JpTokenizerSentencePiece  0.958842  0.958842  0.962460  0.958842  0.954319   \n",
       "JpTokenizerMeCab          0.952058  0.949344  0.947083  0.945726  0.948892   \n",
       "\n",
       "times                     ...        93        94        95        96  \\\n",
       "tokenizer                 ...                                           \n",
       "JpTokenizerSentencePiece  ...  0.956581  0.955224  0.952510  0.949344   \n",
       "JpTokenizerMeCab          ...  0.945274  0.944369  0.945274  0.938489   \n",
       "\n",
       "times                           97        98        99       100       mean  \\\n",
       "tokenizer                                                                     \n",
       "JpTokenizerSentencePiece  0.952510  0.955676  0.956128  0.962913  95.578924   \n",
       "JpTokenizerMeCab          0.945274  0.947083  0.950701  0.950701  94.865219   \n",
       "\n",
       "times                          std  \n",
       "tokenizer                           \n",
       "JpTokenizerSentencePiece  0.374516  \n",
       "JpTokenizerMeCab          0.462855  \n",
       "\n",
       "[2 rows x 102 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = acc_df.dropna().T.copy()\n",
    "acc[\"mean\"] = acc.mean(axis=1)\n",
    "acc[\"std\"] = acc.std(axis=1)\n",
    "acc[\"mean\"] *= 100\n",
    "acc[\"std\"] *= 100\n",
    "acc.sort_values(\"mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JpTokenizerMeCab: 94.9 % (0.5 %)\n",
      "JpTokenizerSentencePiece: 95.6 % (0.4 %)\n"
     ]
    }
   ],
   "source": [
    "for tkr, m, s in acc[[\"mean\", \"std\"]].reset_index().values:\n",
    "    print(f\"{tkr}: {m:.1f} % ({s:.1f} %)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正規性の検定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JpTokenizerMeCab 0.9839680790901184 0.2669599950313568 False 非棄却\n",
      "JpTokenizerSentencePiece 0.9881190061569214 0.5170230269432068 False 非棄却\n"
     ]
    }
   ],
   "source": [
    "for tkr in acc_df.columns:\n",
    "    W, pvalue = scipy.stats.shapiro(acc_df[tkr].dropna())\n",
    "    print(tkr, W, pvalue, pvalue < 0.05, \"棄却\" if pvalue < 0.05 else \"非棄却\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正規乱数で検定に必要なサンプルサイズを評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9098219275474548, 0.27977025508880615)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正規乱数 サンプルサイズ=10\n",
    "x = numpy.random.normal(0, 1, 10)\n",
    "scipy.stats.shapiro(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9824507832527161, 0.20535781979560852)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正規乱数 サンプルサイズ=100\n",
    "x = numpy.random.normal(0, 1, 100)\n",
    "scipy.stats.shapiro(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8532965183258057, 0.06357227265834808)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一様乱数 サンプルサイズ=10\n",
    "x = numpy.random.uniform(0, 1, 10)\n",
    "scipy.stats.shapiro(x)  # <- 棄却できず"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9346017241477966, 0.008286652155220509)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一様乱数 サンプルサイズ=50\n",
    "x = numpy.random.uniform(0, 1, 50)\n",
    "scipy.stats.shapiro(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9585599899291992, 0.003178815357387066)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一様乱数 サンプルサイズ=100\n",
    "x = numpy.random.uniform(0, 1, 100)\n",
    "scipy.stats.shapiro(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- サンプルサイズ=10 では、正規分布からのサンプルであることを否定するのは難しそう\n",
    "    - サンプルサイズ=100 でやり直した\n",
    "    - やり直した結果、正規性は棄却されなかった\n",
    "        - i.e. 正規性があると考えても(測定データと)矛盾しない\n",
    "- 50サンプルで、ギリギリな印象\n",
    "- 結果的に、50-100サンプルは正規性を否定できるためのサンプルとして取得したい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t検定（対応あり）\n",
    "- MeCab, SentencePiece の2群のみを比較するため、t検定でよい\n",
    "- t検定は、正規性に頑健性があるので、参考として実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JpTokenizerMeCab JpTokenizerSentencePiece -18.456124412176518 8.098020258517182e-34 True\n",
      "JpTokenizerSentencePiece JpTokenizerMeCab 18.456124412176518 8.098020258517182e-34 True\n"
     ]
    }
   ],
   "source": [
    "cols = acc_df.columns\n",
    "for base in cols:\n",
    "    for target in [trg for trg in cols if trg != base]:\n",
    "        t, pvalue = scipy.stats.ttest_rel(acc_df[base], acc_df[target])\n",
    "        if pvalue < 0.05:\n",
    "            print(base, target, t, pvalue, (pvalue < 0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ウィルコクソンの符号順位検定\n",
    "- 両側検定\n",
    "- 連続補正なし（精度は、離散分布ではないため）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JpTokenizerMeCab JpTokenizerSentencePiece 2.0 8.834559079893054e-18 True\n",
      "JpTokenizerSentencePiece JpTokenizerMeCab 2.0 8.834559079893054e-18 True\n"
     ]
    }
   ],
   "source": [
    "cols = acc_df.columns\n",
    "for base in cols:\n",
    "    for target in [trg for trg in cols if trg != base]:\n",
    "        w, pvalue = scipy.stats.wilcoxon(acc_df[base], acc_df[target], correction=False)\n",
    "        if pvalue < 0.05:\n",
    "            print(base, target, w, pvalue, (pvalue < 0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 検定結果\n",
    "\n",
    "- t検定も、ウィルコクソンの符号順位和検定のいずれも、有意差がある結果になった\n",
    "\n",
    "| tokenizer name | accuracy mean (std) |\n",
    "| --------------- | --- |\n",
    "| JpTokenizerMeCab | 95.0 (0.5) |\n",
    "| JpTokenizerSentencePiece | 95.6 (0.4) |\n",
    "\n",
    "- MeCab の平均が、$95.0 \\% (\\pm 0.5 \\%)$、SentencePiece の平均が $95.6 \\% (\\pm 0.4 \\%)$ \n",
    "    - 精度は、MeCab < SentencePiece\n",
    "    - 精度差は、偶然ではかなり発生しづらく（0.7%未満）、何らかの意味・理由があると言える"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "- MeCab, SentencePiece の精度を比較すると、有意に、SentencePiece の方が(約0.6%)よい\n",
    "- 精度と実行時間の関係は、以下のようになる\n",
    "    \n",
    "| tokenizer name | accuracy mean (std) | elapsed time mean (std) | cpu time mean (std) |\n",
    "| -------------- | --- | ----------------------- | ------------------- |\n",
    "| JpTokenizerMeCab | 94.9 % (0.5 %) | 1.0 min (0.6 sec) | 4.9 min (4.0 sec) |\n",
    "| JpTokenizerSentencePiece | 95.6 % (0.4 %) | 1.6 min (0.7 sec) | 9.0 min (4.8 sec) |\n",
    "\n",
    "\n",
    "- 経過時間（elapsed time）を、比較すると 約 0.6 min = 36 sec の差であった\n",
    "- CPU時間（cpu time）を、比較すると 約 4.9 min, 9.0 min と、倍近く差がある\n",
    "    - これは、SentencePiece が、マルチCPUで動作することが起因していると考えられる\n",
    "        - 故に、CPU時間が倍近くになっている\n",
    "    - MeCab 単体は、1 cpu で動作するが、SentencePiece の学習（fit()）は、8 cpu で動作することがCPU時間に影響を与えていると考える\n",
    "    - 形態素解析(MeCab, SentencePiece)後のpipeline は、同じである（いずれも途中から8cpu を利用する）\n",
    "- 以上をまとめると\n",
    "    - 計算資源が十分（2 cpu 以上）ある場合は、経過時間の差は大きくない（いずれも実用に耐えうる）\n",
    "    - 計算資源が十分な場合は、若干だがより精度が高い SentencePiece を利用してよく\n",
    "    - 計算資源が1cpuに限られている場合で、経過時間を優先すべきときは、MeCab を利用した方が良さそうである\n",
    "        - 例： 1cpu だと、CPU時間≒経過時間になるため、倍ぐらいの時間差がでる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
